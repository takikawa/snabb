-- -*- lua -*-
-- Implementation of SipHash, based on the reference implementation.
-- See https://131002.net/siphash/ for more details.

module(..., package.seeall)

local bit  = require("bit")
local dasm = require("dasm")
local ffi  = require("ffi")

local debug = false

|.arch x64
|.actionlist actions

-- the definitions here (anchor, assemble, gen) are borrowed from lwaftr
-- (see multi_copy.lua)
__anchor = {}

local function finish (name, prototype, Dst)
   local mcode, size = Dst:build()
   table.insert(__anchor, mcode)
   if debug then
      print("mcode dump: "..name)
      dasm.dump(mcode, size)
   end
   return ffi.cast(prototype, mcode)
end

-- SipHash is a family of hash functions, parameterized by the number
-- of rounds that run per 8-byte input block and the number of rounds
-- that run at the end.  Because we use SipHash as a hash function for
-- fixed-sized inputs, we can simplify processing of the tail word.
-- This simplification is enabled unless a true value for
-- "as_specified" is passed.

function random_sip_hash_key()
   error('unimplemented')
end

function reference_sip_hash_key()
   return ffi.new('uint8_t[16]',
                  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)
end

local function load_initial_state(key)
   -- Initial state constants.
   local state = ffi.new('uint64_t[4]',
			 { 0x736f6d6570736575ULL,
			   0x646f72616e646f6dULL,
			   0x6c7967656e657261ULL,
			   0x7465646279746573ULL })

   -- Mix key into state constants.
   key = ffi.cast('uint64_t*', key or reference_sip_hash_key())
   state[0] = bit.bxor(state[0], key[0])
   state[1] = bit.bxor(state[1], key[1])
   state[2] = bit.bxor(state[2], key[0])
   state[3] = bit.bxor(state[3], key[1])

   return state
end

local function X86_64()
   local asm = {}
   local Dst
   local allregs = {"rax", "rcx", "rdx", "rbx", "rsp", "rbp", "rsi", "rdi",
		    "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15"}
   local regnums = {}
   for i,reg in ipairs(allregs) do regnums[reg] = i-1 end
   -- Map value indexes from the program to registers.  Don't allocate
   -- to rdi; it's the input data.
   local scratchregs = {"r8", "r9", "r10", "r11", "rax", "rcx", "rdx", "rsi"}
   local function regnum(n) return assert(regnums[assert(scratchregs[n+1])]) end

   function asm.init(key)
      local initial_state = load_initial_state(key)
      table.insert(__anchor, initial_state)
      | mov64 Rq(regnum(0)), initial_state[0]
      | mov64 Rq(regnum(1)), initial_state[1]
      | mov64 Rq(regnum(2)), initial_state[2]
      | mov64 Rq(regnum(3)), initial_state[3]
   end
   function asm.add(dst, other)
      | add Rq(regnum(dst)), Rq(regnum(other))
   end
   function asm.shl(reg, bits)
      | shl Rq(regnum(reg)), bits
   end
   function asm.ior(dst, other)
      | or Rq(regnum(dst)), Rq(regnum(other))
   end
   function asm.xor(dst, other)
      | xor Rq(regnum(dst)), Rq(regnum(other))
   end
   function asm.rol(reg, bits)
      | rol Rq(regnum(reg)), bits
   end
   function asm.load_u64_and_advance(dst)
      | mov Rq(regnum(dst)), [rdi]
      | add rdi, 8
   end
   function asm.load_u32_and_advance(dst)
      -- Automatically zero-extending.
      | mov Rd(regnum(dst)), [rdi]
      | add rdi, 4
   end
   function asm.load_u16_and_advance(dst)
      | movzx Rq(regnum(dst)), word [rdi]
      | add rdi, 2
   end
   function asm.load_u8_and_advance(dst)
      | movzx Rq(regnum(dst)), byte [rdi]
      | add rdi, 1
   end
   function asm.load_imm8(dst, imm)
      | xor Rq(regnum(dst)), Rq(regnum(dst))
      if imm ~= 0 then
         | mov Rb(regnum(dst)), imm
      end
   end
   function asm.ret(reg)
      if regnum(reg) ~= regnums["rax"] then
         | mov rax, Rq(regnum(reg))
      end
      | shr rax, 32
      | ret
   end
   function asm:assemble(name, gen)
      Dst = dasm.new(actions)
      gen(self)
      return finish(name.."_x86_64",
		    ffi.typeof("uint32_t (*)(uint8_t *)"),
		    Dst)
   end
   return asm
end

local function SSE(stride)
   local asm = {}
   local Dst
   function asm.init(key)
      local initial_state = load_initial_state(key)
      table.insert(__anchor, initial_state)
      | mov rax, initial_state
      | movddup xmm0, [rax]
      | movddup xmm1, [rax+8]
      | movddup xmm2, [rax+16]
      | movddup xmm3, [rax+24]
   end
   function asm.add(dst, other)
      | paddq xmm(dst), xmm(other)
   end
   function asm.shl(reg, bits)
      | psllq xmm(reg), bits
   end
   function asm.ior(dst, other)
      | por xmm(dst), xmm(other)
   end
   function asm.xor(dst, other)
      | pxor xmm(dst), xmm(other)
   end
   function asm.rol(reg, bits)
      | movupd xmm5, xmm(reg)
      | psllq xmm5, bits
      | psrlq xmm(reg), (64 - bits)
      | por xmm(reg), xmm5
   end
   function asm.load_u64_and_advance(dst)
      | movlpd xmm(dst), qword [rdi]
      | movhpd xmm(dst), qword [rdi+stride]
      | add rdi, 8
   end
   function asm.load_u32_and_advance(dst)
      | movss xmm(dst), dword [rdi]
      | pinsrd xmm(dst), dword [rdi + stride], 2
      | add rdi, 4
   end
   function asm.load_u16_and_advance(dst)
      | pxor xmm(dst), xmm(dst)
      | pinsrw xmm(dst), word [rdi], 0
      | pinsrw xmm(dst), word [rdi + stride], 4
      | add rdi, 2
   end
   function asm.load_u8_and_advance(dst)
      | pxor xmm(dst), xmm(dst)
      | pinsrb xmm(dst), byte [rdi], 0
      | pinsrb xmm(dst), byte [rdi + stride], 8
      | add rdi, 1
   end
   function asm.load_imm8(dst, imm)
      | xor rax, rax
      if imm ~= 0 then
         | mov al, imm
      end
      | pinsrq xmm(dst), rax, 0
      | pinsrq xmm(dst), rax, 1
   end
   function asm.ret(reg)
      -- Extract high 32 bits from each 64-bit value to uint32_t[2] in
      -- rsi.
      | pextrd dword [rsi], xmm(reg), 1
      | pextrd dword [rsi+4], xmm(reg), 3
      | xor rax, rax
      | ret
   end
   function asm:assemble(name, gen)
      Dst = dasm.new(actions)
      gen(self)
      return finish(name.."_sse",
		    ffi.typeof("void (*)(uint8_t *, uint32_t *)"),
		    Dst)
   end
   return asm
end

local function AVX2(stride)
   local asm = {}
   local Dst
   function asm.init(key)
      local initial_state = load_initial_state(key)
      table.insert(__anchor, initial_state)
      | vzeroupper
      | mov rax, initial_state
      | vbroadcastsd ymm0, qword [rax]
      | vbroadcastsd ymm1, qword [rax+8]
      | vbroadcastsd ymm2, qword [rax+16]
      | vbroadcastsd ymm3, qword [rax+24]
   end
   function asm.add(dst, other)
      | vpaddq ymm(dst), ymm(dst), ymm(other)
   end
   function asm.shl(reg, bits)
      | vpsllq ymm(reg), ymm(reg), bits
   end
   function asm.ior(dst, other)
      | vpor ymm(dst), ymm(dst), ymm(other)
   end
   function asm.xor(dst, other)
      | vpxor ymm(dst), ymm(dst), ymm(other)
   end
   function asm.rol(reg, bits)
      | vpsllq ymm5, ymm(reg), bits
      | vpsrlq ymm(reg), ymm(reg), (64 - bits)
      | vpor ymm(reg), ymm(reg), ymm5
   end
   function asm.load_u64_and_advance(dst)
      -- Though we could use a parallel load here, I understand that
      -- it decomposes into approximately the same number of uops as
      -- this.  Note that we load u64 words into DST in the
      -- interleaved order 0, 2, 1, 3; this makes the return sequence
      -- easier.
      assert(dst > 5)
      | vpinsrq xmm(dst), xmm(dst), qword [rdi], 0
      | vpinsrq xmm5, xmm5, qword [rdi+stride], 0
      | vpinsrq xmm(dst), xmm(dst), qword [rdi+stride*2], 1
      | vpinsrq xmm5, xmm5, qword [rdi+stride*3], 1
      | vinsertf128 ymm(dst), ymm(dst), xmm5, 1
      | add rdi, 8
   end
   function asm.load_u32_and_advance(dst)
      assert(dst > 5)
      | mov eax, [rdi]
      | mov edx, [rdi+stride]
      | vpinsrq xmm(dst), xmm(dst), rax, 0
      | vpinsrq xmm5, xmm5, rdx, 0
      | mov eax, [rdi+stride*2]
      | mov edx, [rdi+stride*3]
      | vpinsrq xmm(dst), xmm(dst), rax, 1
      | vpinsrq xmm5, xmm5, rdx, 1
      | vinsertf128 ymm(dst), ymm(dst), xmm5, 1
      | add rdi, 4
   end
   function asm.load_u16_and_advance(dst)
      assert(dst > 5)
      | movzx rax, word [rdi]
      | movzx rdx, word [rdi+stride]
      | vpinsrq xmm(dst), xmm(dst), rax, 0
      | vpinsrq xmm5, xmm5, rdx, 0
      | movzx rax, word [rdi+stride*2]
      | movzx rdx, word [rdi+stride*3]
      | vpinsrq xmm(dst), xmm(dst), rax, 1
      | vpinsrq xmm5, xmm5, rdx, 1
      | vinsertf128 ymm(dst), ymm(dst), xmm5, 1
      | add rdi, 2
   end
   function asm.load_u8_and_advance(dst)
      assert(dst > 5)
      | movzx rax, byte [rdi]
      | movzx rdx, byte [rdi+stride]
      | vpinsrq xmm(dst), xmm(dst), rax, 0
      | vpinsrq xmm5, xmm5, rdx, 0
      | movzx rax, byte [rdi+stride*2]
      | movzx rdx, byte [rdi+stride*3]
      | vpinsrq xmm(dst), xmm(dst), rax, 1
      | vpinsrq xmm5, xmm5, rdx, 1
      | vinsertf128 ymm(dst), ymm(dst), xmm5, 1
      | add rdi, 1
   end
   function asm.load_imm8(dst, imm)
      | xor rax, rax
      if imm ~= 0 then
         | mov al, imm
      end
      | vpinsrq xmm(dst), xmm(dst), rax, 0
      | vpinsrq xmm(dst), xmm(dst), rax, 1
      | vinsertf128 ymm(dst), ymm(dst), xmm(dst), 1
   end
   function asm.ret(reg)
      -- Extract high 32 bits from each 64-bit value.
      | vextractf128 xmm5, ymm(reg), 1
      | vpunpckhdq xmm(reg), xmm(reg), xmm5
      -- Now write to uint32_t[4] in rsi.
      | vmovdqu oword [rsi], xmm(reg)
      | vzeroupper
      | ret
   end
   function asm:assemble(name, gen)
      Dst = dasm.new(actions)
      gen(self)
      return finish(name.."_avx2",
		    ffi.typeof("void (*)(uint8_t *, uint32_t *)"),
		    Dst)
   end
   return asm
end

local function Simulator()
   local asm = {}
   local input, output
   local state
   function asm.init(key)
      local initial_state = load_initial_state(key)
      state = ffi.new('uint64_t[8]')
      for i=0,3 do state[i] = initial_state[i] end
   end
   function asm.add(dst, other)
      state[dst] = state[dst] + state[other]
   end
   function asm.shl(reg, bits)
      state[reg] = bit.lshift(state[reg], bits)
   end
   function asm.ior(dst, other)
      state[dst] = bit.bor(state[dst], state[other])
   end
   function asm.xor(dst, other)
      state[dst] = bit.bxor(state[dst], state[other])
   end
   function asm.rol(reg, bits)
      state[reg] = bit.rol(state[reg], bits)
   end
   function asm.load_u64_and_advance(dst)
      state[dst] = ffi.cast('uint64_t*', input)[0]
      input = input + 8
   end
   function asm.load_u32_and_advance(dst)
      state[dst] = ffi.cast('uint32_t*', input)[0]
      input = input + 4
   end
   function asm.load_u16_and_advance(dst)
      state[dst] = ffi.cast('uint16_t*', input)[0]
      input = input + 2
   end
   function asm.load_u8_and_advance(dst)
      state[dst] = input[0]
      input = input + 1
   end
   function asm.load_imm8(dst, imm)
      state[dst] = imm
   end
   function asm.ret(reg)
      output = tonumber(bit.rshift(state[reg], 32))
   end
   function asm:assemble(name, gen)
      return function(ptr)
	 input, output = ffi.cast('uint8_t*', ptr), nil
	 gen(self)
	 input = nil
	 return output
      end
   end
   return asm
end

function make_sip_hash_x(assembler, size, key, c, d, as_specified)
   c = c or 2
   d = d or 4
   function gen(asm)
      -- Arguments:
      -- rdi: packed keys as pointer
      -- rsi: output uint32_t[4]
      -- rax: scratch

      -- Registers used:
      -- ymm0-ymm3 map to SipHash variables v0-v3
      -- Other ymm registers are scratch.

      local function sipround()
         asm.add(0, 1)
         asm.rol(1, 13)
         asm.xor(1, 0)
         asm.rol(0, 32)
         asm.add(2, 3)
         asm.rol(3, 16)
         asm.xor(3, 2)
         asm.add(0, 3)
         asm.rol(3, 21)
         asm.xor(3, 0)
         asm.add(2, 1)
         asm.rol(1, 17)
         asm.xor(1, 2)
         asm.rol(2, 32)
      end

      local function process(input)
         asm.xor(3, input)
         for i=1,c do sipround() end
         asm.xor(0, input)
      end

      -- Initialization phase.
      asm.init(key)

      -- Compression phase.
      for i=1,size/8 do
         asm.load_u64_and_advance(6)
         process(6)
      end
      -- Load tail word and process it.
      if as_specified then
         asm.load_imm8(6, bit.band(size, 0xff))
         asm.shl(6, 56)
         for i=1,size%8 do
            asm.load_u8_and_advance(7)
            if i > 1 then asm.shl(7, (i - 1) * 8) end
            asm.ior(6, 7)
         end
         process(6)
      elseif size%8 ~= 0 then
         -- Fixed-size simplification: no need to add in size byte, we
         -- can use different byte orders if it's more convenient, and
         -- we don't have to do anything at all if the size is a
         -- multiple of 8.
         if size%8 >= 4 then
            asm.load_u32_and_advance(6)
         else
            asm.xor(6, 6)
         end
         if size%4 >= 2 then
            asm.load_u16_and_advance(7)
            asm.shl(6, 16)
            asm.ior(6, 7)
         end
         if size%2 ~= 0 then
            asm.load_u8_and_advance(7)
            asm.shl(6, 8)
            asm.ior(6, 7)
         end
         process(6)
      end

      -- Finalization.
      asm.load_imm8(6, 0xff)
      asm.xor(2, 6)
      for i=1,d do sipround() end
      asm.xor(0, 1)
      asm.xor(2, 3)
      asm.xor(0, 2)
      asm.ret(0)
   end

   return assembler(size):assemble("siphash_"..c.."_"..d.."_x", gen)
end

function make_sip_hash_x1(...)
   return make_sip_hash_x(X86_64, ...)
end

function make_sip_hash_x2(...)
   return make_sip_hash_x(SSE, ...)
end

function make_sip_hash_x4(...)
   return make_sip_hash_x(AVX2, ...)
end

local function make_reference_sip_hash(...)
   return make_sip_hash_x(Simulator, ...)
end

function selftest()
   -- test that the lua and dasm versions produce the same output
   local function test(size, key, c, d, as_specified)
      local reference_hash = make_reference_sip_hash(size, key, c, d, as_specified)
      local hash_x1 = make_sip_hash_x1(size, key, c, d, as_specified)
      local hash_x2 = make_sip_hash_x2(size, key, c, d, as_specified)
      local hash_x4 = make_sip_hash_x4(size, key, c, d, as_specified)

      for i=0, 255 do
         local buf = ffi.new("uint8_t[?]", size*4)
	 for stride=0,3 do
	    for j=0, size-1 do
	       buf[j + stride*size] = (i + j) % size
            end
         end
         local ref_result = reference_hash(buf)
	 local x1_result = hash_x1(buf)
         local x2_result = ffi.new("uint32_t[2]")
         hash_x2(buf, x2_result)
         local x4_result = ffi.new("uint32_t[4]")
         hash_x4(buf, x4_result)
         if ref_result ~= x1_result then
            print(size, key, c, d, as_specified, ref_result, x1_result)
            error('scalar result does not match reference')
         end
	 for elt=0,1 do
	    if ref_result ~= x2_result[elt] then
	       print(size, key, c, d, as_specified, ref_result, x2_result[elt])
	       error('x2 result '..elt..' does not match reference')
	    end
	 end
	 for elt=0,3 do
	    if ref_result ~= x4_result[elt] and false then
	       print(size, key, c, d, as_specified, ref_result, x4_result[elt])
	       error('x4 result '..elt..' does not match reference')
	    end
	 end
      end
   end

   local key = reference_sip_hash_key()
   io.stdout:write("selftest: ")
   io.stdout:flush()
   for size=0,32 do
      io.stdout:write(".")
      io.stdout:flush()
      for c=0,2 do
         for d=0,4 do
            for _, as_specified in ipairs({true, false}) do
               test(size, key, c, d, as_specified)
            end
         end
      end
   end
   print("\nselftest ok")
end
